# üé≠ Reconstructing Face Under Mask - ImprovedPremiumGAN

D·ª± √°n s·ª≠ d·ª•ng m·∫°ng **GAN (Generative Adversarial Network)** ƒë·ªÉ t√°i t·∫°o ph·∫ßn khu√¥n m·∫∑t b·ªã che b·ªüi kh·∫©u trang. Model ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n dataset khu√¥n m·∫∑t v√† c√≥ kh·∫£ nƒÉng kh√¥i ph·ª•c l·∫°i v√πng b·ªã che v·ªõi ch·∫•t l∆∞·ª£ng cao.

---

## üìÅ C·∫•u Tr√∫c D·ª± √Ån

```
Reconstructing_face_under_mask/
‚îÇ
‚îú‚îÄ‚îÄ ImprovedPremiumGAN/          # Th∆∞ m·ª•c ch√≠nh ch·ª©a model v√† code training
‚îÇ   ‚îú‚îÄ‚îÄ config.py                # C·∫•u h√¨nh hyperparameters v√† ƒë∆∞·ªùng d·∫´n
‚îÇ   ‚îú‚îÄ‚îÄ model.py                 # Ki·∫øn tr√∫c Generator (U-Net) v√† Discriminator (PatchGAN)
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py               # Dataset loader v√† data augmentation
‚îÇ   ‚îú‚îÄ‚îÄ loss.py                  # VGG Perceptual Loss
‚îÇ   ‚îú‚îÄ‚îÄ train.py                 # Script hu·∫•n luy·ªán ch√≠nh
‚îÇ   ‚îú‚îÄ‚îÄ inference.py             # Script d·ª± ƒëo√°n/inference
‚îÇ   ‚îú‚îÄ‚îÄ detect.py                # Ph√°t hi·ªán v√πng kh·∫©u trang b·∫±ng YOLO
‚îÇ   ‚îú‚îÄ‚îÄ utils.py                 # C√°c h√†m ti·ªán √≠ch (SSIM, PSNR, save images)
‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/             # L∆∞u tr·ªØ model weights
‚îÇ   ‚îî‚îÄ‚îÄ results/                 # K·∫øt qu·∫£ training v√† log
‚îÇ
‚îú‚îÄ‚îÄ dataset/                     # Th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu
‚îÇ   ‚îú‚îÄ‚îÄ with_mask/               # ·∫¢nh khu√¥n m·∫∑t c√≥ kh·∫©u trang
‚îÇ   ‚îî‚îÄ‚îÄ without_mask/            # ·∫¢nh khu√¥n m·∫∑t kh√¥ng kh·∫©u trang (Ground Truth)
‚îÇ
‚îú‚îÄ‚îÄ evaluate.py                  # Script ƒë√°nh gi√° v√† v·∫Ω bi·ªÉu ƒë·ªì metrics
‚îú‚îÄ‚îÄ download_dataset.py          # Script ki·ªÉm tra dataset
‚îú‚îÄ‚îÄ requirements.txt             # Danh s√°ch th∆∞ vi·ªán c·∫ßn thi·∫øt
‚îú‚îÄ‚îÄ yolov8n.pt                   # Pre-trained YOLO model cho mask detection
‚îî‚îÄ‚îÄ README.md                    # T√†i li·ªáu n√†y
```

---

## üèóÔ∏è Ki·∫øn Tr√∫c Model

### 1. Generator - Ki·∫øn Tr√∫c U-Net

Generator s·ª≠ d·ª•ng ki·∫øn tr√∫c **U-Net** v·ªõi c∆° ch·∫ø **skip connections** ƒë·ªÉ b·∫£o to√†n th√¥ng tin chi ti·∫øt t·ª´ ·∫£nh ƒë·∫ßu v√†o.

```
Input (3, 128, 128)
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ENCODER (Downsampling)                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  DoubleConv(3 ‚Üí 64)   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ       ‚îÇ MaxPool2d                                ‚îÇ       ‚îÇ
‚îÇ       ‚ñº                                          ‚îÇ       ‚îÇ
‚îÇ  DoubleConv(64 ‚Üí 128)  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ       ‚îÇ
‚îÇ       ‚îÇ MaxPool2d                            ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ       ‚ñº                                      ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ  DoubleConv(128 ‚Üí 256) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ       ‚îÇ MaxPool2d                       ‚îÇ    ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ       ‚ñº                                 ‚îÇ    ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ  DoubleConv(256 ‚Üí 512) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ    ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ       ‚îÇ MaxPool2d                  ‚îÇ    ‚îÇ    ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ       ‚ñº                            ‚îÇ    ‚îÇ    ‚îÇ   ‚îÇ       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ              BOTTLENECK            ‚îÇ    ‚îÇ    ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ  DoubleConv(512 ‚Üí 1024)            ‚îÇ    ‚îÇ    ‚îÇ   ‚îÇ       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                    DECODER (Upsampling)                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ConvTranspose2d(1024 ‚Üí 512)       ‚îÇ    ‚îÇ    ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ       ‚îÇ Concat ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ    ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ  DoubleConv(1024 ‚Üí 512)                 ‚îÇ    ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ       ‚îÇ                                  ‚îÇ    ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ       ‚ñº                                  ‚îÇ    ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ  ConvTranspose2d(512 ‚Üí 256)             ‚îÇ    ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ       ‚îÇ Concat ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ  DoubleConv(512 ‚Üí 256)                       ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ       ‚îÇ                                       ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ       ‚ñº                                       ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ  ConvTranspose2d(256 ‚Üí 128)                  ‚îÇ   ‚îÇ       ‚îÇ
‚îÇ       ‚îÇ Concat ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ       ‚îÇ
‚îÇ  DoubleConv(256 ‚Üí 128)                           ‚îÇ       ‚îÇ
‚îÇ       ‚îÇ                                           ‚îÇ       ‚îÇ
‚îÇ       ‚ñº                                           ‚îÇ       ‚îÇ
‚îÇ  ConvTranspose2d(128 ‚Üí 64)                       ‚îÇ       ‚îÇ
‚îÇ       ‚îÇ Concat ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ  DoubleConv(128 ‚Üí 64)                                    ‚îÇ
‚îÇ       ‚îÇ                                                   ‚îÇ
‚îÇ       ‚ñº                                                   ‚îÇ
‚îÇ  Conv2d(64 ‚Üí 3) + Tanh()                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
Output (3, 128, 128) ‚àà [-1, 1]
```

**DoubleConv Block:**

```
Conv2d(3√ó3) ‚Üí BatchNorm2d ‚Üí ReLU ‚Üí Conv2d(3√ó3) ‚Üí BatchNorm2d ‚Üí ReLU
```

---

### 2. Discriminator - Ki·∫øn Tr√∫c PatchGAN

Discriminator s·ª≠ d·ª•ng ki·∫øn tr√∫c **PatchGAN** - thay v√¨ ƒë·∫ßu ra l√† m·ªôt gi√° tr·ªã scalar (real/fake), n√≥ ƒë∆∞a ra m·ªôt **grid NxN** c√°c x√°c su·∫•t, gi√∫p model focus v√†o c√°c chi ti·∫øt c·ª•c b·ªô (texture, edges).

```
Input (3, 128, 128)
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Conv2d(3 ‚Üí 64, k=4, s=2)          ‚îÇ  ‚Üí 64√ó64√ó64
‚îÇ  LeakyReLU(0.2)                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  CNNBlock(64 ‚Üí 128, s=2)           ‚îÇ  ‚Üí 32√ó32√ó128
‚îÇ  CNNBlock(128 ‚Üí 256, s=2)          ‚îÇ  ‚Üí 16√ó16√ó256
‚îÇ  CNNBlock(256 ‚Üí 512, s=2)          ‚îÇ  ‚Üí 8√ó8√ó512
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Conv2d(512 ‚Üí 1, k=4, s=1)         ‚îÇ  ‚Üí 7√ó7√ó1
‚îÇ  Sigmoid()                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
Output: 7√ó7 Probability Grid
```

**CNNBlock:**

```
Conv2d(4√ó4, padding_mode="reflect") ‚Üí BatchNorm2d ‚Üí LeakyReLU(0.2)
```

---

## üìâ H√†m Loss (Loss Functions)

D·ª± √°n s·ª≠ d·ª•ng **3 lo·∫°i Loss** k·∫øt h·ª£p ƒë·ªÉ hu·∫•n luy·ªán Generator:

### 1. Adversarial Loss (BCE Loss)

```python
L_adv = BCE(D(G(x)), 1)  # Generator c·ªë g·∫Øng ƒë√°nh l·ª´a Discriminator
```

- **M·ª•c ƒë√≠ch**: Khi·∫øn ·∫£nh sinh ra "gi·ªëng th·∫≠t" theo ƒë√°nh gi√° c·ªßa Discriminator
- **Weight**: `LAMBDA_ADV = 1`

### 2. L1 Loss (Pixel-wise Reconstruction)

```python
L_L1 = ||G(x) - y||‚ÇÅ
```

- **M·ª•c ƒë√≠ch**: ƒê·∫£m b·∫£o ·∫£nh sinh ra gi·ªëng v·ªõi Ground Truth ·ªü m·ª©c pixel
- **Weight**: `LAMBDA_L1 = 100`
- **T√°c d·ª•ng**: Gi·ªØ c·∫•u tr√∫c t·ªïng th·ªÉ, tr√°nh blur

### 3. VGG Perceptual Loss

```python
L_VGG = Œ£ ||VGG_i(G(x)) - VGG_i(y)||¬≤
```

- **M·ª•c ƒë√≠ch**: So s√°nh features ·ªü nhi·ªÅu m·ª©c ƒë·ªô tr·ª´u t∆∞·ª£ng (texture, edges, semantic)
- **Weight**: `LAMBDA_VGG = 10`
- **C√°c layer VGG19 ƒë∆∞·ª£c s·ª≠ d·ª•ng**:
  - `relu1_1` (low-level: edges)
  - `relu2_1` (textures)
  - `relu3_1` (patterns)
  - `relu4_1` (semantic features)
  - `relu5_1` (high-level semantic)

### T·ªïng Loss c·ªßa Generator:

```python
L_G = LAMBDA_ADV √ó L_adv + LAMBDA_L1 √ó L_L1 + LAMBDA_VGG √ó L_VGG
```

### Discriminator Loss:

```python
L_D = (BCE(D(y), 1) + BCE(D(G(x)), 0)) / 2
```

---

## ‚öôÔ∏è Optimizer

### Adam Optimizer

C·∫£ Generator v√† Discriminator ƒë·ªÅu s·ª≠ d·ª•ng **Adam Optimizer** v·ªõi c·∫•u h√¨nh:

| Parameter     | Generator | Discriminator |
| ------------- | --------- | ------------- |
| Learning Rate | 0.0002    | 0.0002        |
| Beta1         | 0.5       | 0.5           |
| Beta2         | 0.999     | 0.999         |

**L√Ω do ch·ªçn Beta1 = 0.5:**

- Gi·∫£m momentum so v·ªõi m·∫∑c ƒë·ªãnh (0.9)
- Gi√∫p ·ªïn ƒë·ªãnh training GAN, tr√°nh oscillation

---

## üõ†Ô∏è K·ªπ Thu·∫≠t Training

### 1. Learning Rate Scheduler

```python
ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)
```

- Gi·∫£m LR ƒëi 50% n·∫øu loss kh√¥ng c·∫£i thi·ªán sau 5 epochs
- Gi√∫p fine-tune model ·ªü giai ƒëo·∫°n cu·ªëi

### 2. Synthetic Mask Generation

Thay v√¨ s·ª≠ d·ª•ng ·∫£nh c√≥ mask th·∫≠t, d·ª± √°n t·∫°o **mask t·ªïng h·ª£p** trong qu√° tr√¨nh training:

```python
# V√πng mask: 50%-95% chi·ªÅu cao, 15%-85% chi·ªÅu r·ªông
mask_y_start = int(h * 0.50)
mask_y_end = int(h * 0.95)
mask_x_start = int(w * 0.15)
mask_x_end = int(w * 0.85)

# ƒê·∫∑t v√πng mask th√†nh m√†u ƒëen (-1 trong range [-1, 1])
masked_image[:, mask_y_start:mask_y_end, mask_x_start:mask_x_end] = -1.0
```

### 3. Weight Initialization

```python
# Normal distribution v·ªõi mean=0, std=0.02
nn.init.normal_(m.weight.data, 0.0, 0.02)
```

- √Åp d·ª•ng cho: Conv2d, ConvTranspose2d, BatchNorm2d

### 4. Checkpoint & Resume Training

- L∆∞u checkpoint m·ªói epoch
- C√≥ kh·∫£ nƒÉng resume training t·ª´ checkpoint cu·ªëi c√πng
- L∆∞u c·∫£ `state_dict` v√† `optimizer` state

### 5. Image Normalization

```python
# Input/Output range: [-1, 1]
transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
```

### 6. Real-time Metrics Tracking

- **SSIM** (Structural Similarity Index): ƒê√°nh gi√° ƒë·ªô t∆∞∆°ng ƒë·ªìng c·∫•u tr√∫c
- **PSNR** (Peak Signal-to-Noise Ratio): ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng t√°i t·∫°o
- K·∫øt qu·∫£ ƒë∆∞·ª£c log ra file CSV

---

## üìä Metrics ƒê√°nh Gi√°

| Metric       | M√¥ t·∫£                                                   | Gi√° tr·ªã t·ªët                     |
| ------------ | ------------------------------------------------------- | ------------------------------- |
| **SSIM**     | ƒê·ªô t∆∞∆°ng ƒë·ªìng c·∫•u tr√∫c (luminance, contrast, structure) | C√†ng g·∫ßn 1 c√†ng t·ªët             |
| **PSNR**     | T·ª∑ l·ªá t√≠n hi·ªáu tr√™n nhi·ªÖu (dB)                          | > 20 dB l√† t·ªët, > 30 dB r·∫•t t·ªët |
| **L1 Loss**  | Sai s·ªë pixel trung b√¨nh                                 | C√†ng th·∫•p c√†ng t·ªët              |
| **VGG Loss** | Sai s·ªë perceptual                                       | C√†ng th·∫•p c√†ng t·ªët              |

---

## üöÄ H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng

### 1. C√†i ƒë·∫∑t th∆∞ vi·ªán

```bash
pip install -r requirements.txt
```

### 2. Chu·∫©n b·ªã d·ªØ li·ªáu

ƒê·∫∑t ·∫£nh khu√¥n m·∫∑t v√†o th∆∞ m·ª•c `dataset/without_mask/`

### 3. Training

```bash
cd ImprovedPremiumGAN
python train.py
```

### 4. Inference

```bash
# ƒê·∫∑t ·∫£nh test v√†o dataset/test_images/
python inference.py
```

---

## üìà Hyperparameters

| Parameter       | Gi√° tr·ªã | M√¥ t·∫£                       |
| --------------- | ------- | --------------------------- |
| `IMG_SIZE`      | 128√ó128 | K√≠ch th∆∞·ªõc ·∫£nh input/output |
| `BATCH_SIZE`    | 16      | S·ªë ·∫£nh m·ªói batch            |
| `NUM_EPOCHS`    | 100     | S·ªë epoch t·ªëi ƒëa             |
| `LEARNING_RATE` | 0.0002  | Learning rate cho c·∫£ G v√† D |
| `LAMBDA_L1`     | 100     | Weight cho L1 Loss          |
| `LAMBDA_VGG`    | 10      | Weight cho VGG Loss         |
| `LAMBDA_ADV`    | 1       | Weight cho Adversarial Loss |
| `TRAIN_RATIO`   | 0.9     | T·ª∑ l·ªá train/test split      |

---

## üîç Mask Detection (YOLO)

S·ª≠ d·ª•ng **YOLOv8** ƒë·ªÉ ph√°t hi·ªán v√πng khu√¥n m·∫∑t v√† x√°c ƒë·ªãnh v√πng mask:

- Detect bounding box c·ªßa ng∆∞·ªùi
- ∆Ø·ªõc t√≠nh v√πng mask = n·ª≠a d∆∞·ªõi khu√¥n m·∫∑t
- Fallback: n·∫øu kh√¥ng detect ƒë∆∞·ª£c, s·ª≠ d·ª•ng t·ªça ƒë·ªô c·ªë ƒë·ªãnh

---


